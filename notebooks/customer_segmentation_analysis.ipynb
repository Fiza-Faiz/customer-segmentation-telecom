{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation Analysis for Telecommunications\n",
    "\n",
    "## Project Overview\n",
    "This notebook implements customer segmentation using machine learning techniques to identify distinct customer groups based on their behavior, demographics, and usage patterns in the telecommunications industry.\n",
    "\n",
    "## Business Objective\n",
    "- Identify customer segments with different characteristics and behaviors\n",
    "- Understand which segments are more likely to purchase certain services\n",
    "- Provide actionable insights for targeted marketing and retention strategies\n",
    "- Reduce customer churn by understanding customer needs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import silhouette_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Additional preprocessing tools\n",
    "from category_encoders import TargetEncoder\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Set style for visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/telecom_customer_churn.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "display(df.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Check unique values for categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nCategorical columns: {categorical_cols}\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing\n",
    "\n",
    "### Challenge 1: Mixed Data Types\n",
    "The dataset contains both numerical and categorical features. We need to handle them appropriately for machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Challenge: TotalCharges column is object type but should be numeric\n",
    "print(f\"TotalCharges data type: {df_clean['TotalCharges'].dtype}\")\n",
    "print(f\"Sample TotalCharges values: {df_clean['TotalCharges'].head()}\")\n",
    "\n",
    "# Check for non-numeric values\n",
    "non_numeric = df_clean[df_clean['TotalCharges'] == ' ']\n",
    "print(f\"\\nRows with empty TotalCharges: {len(non_numeric)}\")\n",
    "\n",
    "# Solution: Convert to numeric and handle empty strings\n",
    "df_clean['TotalCharges'] = df_clean['TotalCharges'].replace(' ', np.nan)\n",
    "df_clean['TotalCharges'] = pd.to_numeric(df_clean['TotalCharges'])\n",
    "\n",
    "# For customers with NaN TotalCharges, we can infer it might be new customers\n",
    "# Let's check their tenure\n",
    "print(f\"\\nTenure for customers with missing TotalCharges:\")\n",
    "print(df_clean[df_clean['TotalCharges'].isna()]['tenure'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for missing TotalCharges: Use MonthlyCharges * tenure for estimation\n",
    "mask = df_clean['TotalCharges'].isna()\n",
    "df_clean.loc[mask, 'TotalCharges'] = df_clean.loc[mask, 'MonthlyCharges'] * df_clean.loc[mask, 'tenure']\n",
    "\n",
    "print(f\"Missing values after cleaning: {df_clean.isnull().sum().sum()}\")\n",
    "print(f\"TotalCharges data type after cleaning: {df_clean['TotalCharges'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges', 'SeniorCitizen']\n",
    "categorical_cols = [col for col in df_clean.columns if col not in numerical_cols + ['customerID']]\n",
    "\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Check for outliers in numerical columns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    axes[i].boxplot(df_clean[col].dropna())\n",
    "    axes[i].set_title(f'Boxplot of {col}')\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/outlier_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Handling Categorical Variables\n",
    "We have multiple categorical variables with different cardinalities that need proper encoding for ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical variables\n",
    "print(\"Categorical Variable Analysis:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique values: {df_clean[col].nunique()}\")\n",
    "    print(f\"  Values: {df_clean[col].unique()}\")\n",
    "    print(f\"  Value counts:\")\n",
    "    print(df_clean[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature engineering pipeline\n",
    "def create_features(df):\n",
    "    \"\"\"Create additional features for better segmentation\"\"\"\n",
    "    df_featured = df.copy()\n",
    "    \n",
    "    # Create tenure groups\n",
    "    df_featured['tenure_group'] = pd.cut(df_featured['tenure'], \n",
    "                                        bins=[0, 12, 24, 36, 48, 100], \n",
    "                                        labels=['0-12', '13-24', '25-36', '37-48', '49+'])\n",
    "    \n",
    "    # Create monthly charges groups\n",
    "    df_featured['monthly_charges_group'] = pd.cut(df_featured['MonthlyCharges'], \n",
    "                                                 bins=4, \n",
    "                                                 labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    \n",
    "    # Create total charges groups\n",
    "    df_featured['total_charges_group'] = pd.cut(df_featured['TotalCharges'], \n",
    "                                               bins=4, \n",
    "                                               labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    \n",
    "    # Average monthly charge (total/tenure)\n",
    "    df_featured['avg_monthly_charge'] = df_featured['TotalCharges'] / (df_featured['tenure'] + 1)\n",
    "    \n",
    "    # Create service count (total number of services)\n",
    "    service_cols = ['PhoneService', 'InternetService', 'OnlineSecurity', 'OnlineBackup', \n",
    "                   'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "    \n",
    "    df_featured['total_services'] = 0\n",
    "    for col in service_cols:\n",
    "        if col == 'InternetService':\n",
    "            df_featured['total_services'] += (df_featured[col] != 'No').astype(int)\n",
    "        else:\n",
    "            df_featured['total_services'] += (df_featured[col] == 'Yes').astype(int)\n",
    "    \n",
    "    # Create internet user flag\n",
    "    df_featured['has_internet'] = (df_featured['InternetService'] != 'No').astype(int)\n",
    "    \n",
    "    # Create phone user flag\n",
    "    df_featured['has_phone'] = (df_featured['PhoneService'] == 'Yes').astype(int)\n",
    "    \n",
    "    return df_featured\n",
    "\n",
    "df_featured = create_features(df_clean)\n",
    "print(f\"Features after engineering: {df_featured.shape[1]}\")\n",
    "print(f\"New features created: {[col for col in df_featured.columns if col not in df_clean.columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer distribution analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Gender distribution\n",
    "df_featured['gender'].value_counts().plot(kind='pie', ax=axes[0], autopct='%1.1f%%')\n",
    "axes[0].set_title('Gender Distribution')\n",
    "\n",
    "# Senior Citizen distribution\n",
    "df_featured['SeniorCitizen'].value_counts().plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Senior Citizen Distribution')\n",
    "axes[1].set_xlabel('Senior Citizen (0=No, 1=Yes)')\n",
    "\n",
    "# Contract type distribution\n",
    "df_featured['Contract'].value_counts().plot(kind='bar', ax=axes[2])\n",
    "axes[2].set_title('Contract Type Distribution')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Internet Service distribution\n",
    "df_featured['InternetService'].value_counts().plot(kind='bar', ax=axes[3])\n",
    "axes[3].set_title('Internet Service Distribution')\n",
    "axes[3].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Churn distribution\n",
    "df_featured['Churn'].value_counts().plot(kind='pie', ax=axes[4], autopct='%1.1f%%')\n",
    "axes[4].set_title('Churn Distribution')\n",
    "\n",
    "# Tenure distribution\n",
    "axes[5].hist(df_featured['tenure'], bins=30, edgecolor='black')\n",
    "axes[5].set_title('Tenure Distribution')\n",
    "axes[5].set_xlabel('Tenure (months)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/customer_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis for numerical features\n",
    "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges', 'total_services', 'avg_monthly_charge']\n",
    "correlation_matrix = df_featured[numerical_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service usage patterns\n",
    "service_columns = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                  'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "\n",
    "service_data = []\n",
    "for service in service_columns:\n",
    "    yes_count = (df_featured[service] == 'Yes').sum()\n",
    "    no_count = (df_featured[service] == 'No').sum()\n",
    "    service_data.append([service, yes_count, no_count])\n",
    "\n",
    "service_df = pd.DataFrame(service_data, columns=['Service', 'Yes', 'No'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(service_columns))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, service_df['Yes'], width, label='Yes', alpha=0.8)\n",
    "plt.bar(x + width/2, service_df['No'], width, label='No', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Services')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.title('Service Usage Patterns')\n",
    "plt.xticks(x, service_columns, rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/service_usage_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing for Machine Learning\n",
    "\n",
    "### Challenge 3: Creating a Pipeline for Mixed Data Types\n",
    "We need to handle numerical and categorical features differently while maintaining the ability to inverse transform for interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for machine learning\n",
    "# Exclude ID and target variable for clustering\n",
    "features_for_clustering = df_featured.drop(['customerID'], axis=1)\n",
    "\n",
    "# Separate features by type\n",
    "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges', 'SeniorCitizen', \n",
    "                     'total_services', 'avg_monthly_charge', 'has_internet', 'has_phone']\n",
    "\n",
    "categorical_features = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
    "                       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
    "                       'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "print(f\"Numerical features ({len(numerical_features)}): {numerical_features}\")\n",
    "print(f\"Categorical features ({len(categorical_features)}): {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Define preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "X_processed = preprocessor.fit_transform(features_for_clustering)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "feature_names = (numerical_features + \n",
    "                list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features)))\n",
    "\n",
    "print(f\"Shape after preprocessing: {X_processed.shape}\")\n",
    "print(f\"Total features after one-hot encoding: {len(feature_names)}\")\n",
    "\n",
    "# Create DataFrame for easier handling\n",
    "X_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "print(f\"\\nFirst few feature names: {feature_names[:10]}\")\n",
    "print(f\"Last few feature names: {feature_names[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for dimensionality reduction and visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_processed)\n",
    "\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.3f}\")\n",
    "\n",
    "# Plot PCA components\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.6)\n",
    "plt.xlabel(f'First Principal Component (Explained Variance: {pca.explained_variance_ratio_[0]:.3f})')\n",
    "plt.ylabel(f'Second Principal Component (Explained Variance: {pca.explained_variance_ratio_[1]:.3f})')\n",
    "plt.title('PCA Visualization of Customer Data')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/pca_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Customer Segmentation with Multiple Algorithms\n",
    "\n",
    "### Challenge 4: Choosing Optimal Number of Clusters\n",
    "We'll use multiple methods to determine the best number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters using Elbow Method and Silhouette Score\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 11)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_processed)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(X_processed, kmeans.labels_))\n",
    "\n",
    "# Plot results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Elbow curve\n",
    "ax1.plot(k_range, inertias, 'bo-')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.set_title('Elbow Method for Optimal k')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Silhouette scores\n",
    "ax2.plot(k_range, silhouette_scores, 'ro-')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Silhouette Score')\n",
    "ax2.set_title('Silhouette Score for Different k')\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/cluster_optimization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find optimal k\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Optimal number of clusters based on silhouette score: {optimal_k}\")\n",
    "print(f\"Silhouette scores: {dict(zip(k_range, silhouette_scores))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means clustering with optimal k\n",
    "optimal_k = 4  # Based on analysis above or business requirements\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_processed)\n",
    "\n",
    "# Add cluster labels to original dataframe\n",
    "df_clustered = df_featured.copy()\n",
    "df_clustered['Cluster'] = cluster_labels\n",
    "\n",
    "print(f\"Clustering completed with {optimal_k} clusters\")\n",
    "print(f\"Silhouette Score: {silhouette_score(X_processed, cluster_labels):.3f}\")\n",
    "print(f\"\\nCluster distribution:\")\n",
    "print(df_clustered['Cluster'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters using PCA\n",
    "plt.figure(figsize=(12, 8))\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "for i in range(optimal_k):\n",
    "    cluster_points = X_pca[cluster_labels == i]\n",
    "    plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "               c=colors[i], label=f'Cluster {i}', alpha=0.7, s=50)\n",
    "\n",
    "plt.xlabel(f'First Principal Component (Explained Variance: {pca.explained_variance_ratio_[0]:.3f})')\n",
    "plt.ylabel(f'Second Principal Component (Explained Variance: {pca.explained_variance_ratio_[1]:.3f})')\n",
    "plt.title('Customer Segments Visualization (PCA)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/customer_segments_pca.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cluster Analysis and Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "def analyze_clusters(df, cluster_col='Cluster'):\n",
    "    \"\"\"Comprehensive cluster analysis\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"CLUSTER PROFILING ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Numerical features analysis\n",
    "    numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges', 'total_services']\n",
    "    \n",
    "    cluster_profiles = df.groupby(cluster_col)[numerical_cols].agg(['mean', 'median', 'std']).round(2)\n",
    "    \n",
    "    print(\"\\nNUMERICAL FEATURES BY CLUSTER:\")\n",
    "    display(cluster_profiles)\n",
    "    \n",
    "    # Categorical features analysis\n",
    "    categorical_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'Contract', \n",
    "                       'InternetService', 'Churn']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\n{col.upper()} DISTRIBUTION BY CLUSTER:\")\n",
    "        cluster_cat = pd.crosstab(df[cluster_col], df[col], normalize='index') * 100\n",
    "        display(cluster_cat.round(1))\n",
    "    \n",
    "    return cluster_profiles\n",
    "\n",
    "cluster_analysis = analyze_clusters(df_clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive cluster visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 1. Tenure by cluster\n",
    "df_clustered.boxplot(column='tenure', by='Cluster', ax=axes[0])\n",
    "axes[0].set_title('Tenure Distribution by Cluster')\n",
    "axes[0].set_xlabel('Cluster')\n",
    "\n",
    "# 2. Monthly charges by cluster\n",
    "df_clustered.boxplot(column='MonthlyCharges', by='Cluster', ax=axes[1])\n",
    "axes[1].set_title('Monthly Charges by Cluster')\n",
    "axes[1].set_xlabel('Cluster')\n",
    "\n",
    "# 3. Total services by cluster\n",
    "df_clustered.boxplot(column='total_services', by='Cluster', ax=axes[2])\n",
    "axes[2].set_title('Total Services by Cluster')\n",
    "axes[2].set_xlabel('Cluster')\n",
    "\n",
    "# 4. Churn rate by cluster\n",
    "churn_by_cluster = df_clustered.groupby('Cluster')['Churn'].apply(lambda x: (x=='Yes').mean()) * 100\n",
    "churn_by_cluster.plot(kind='bar', ax=axes[3])\n",
    "axes[3].set_title('Churn Rate by Cluster (%)')\n",
    "axes[3].set_xlabel('Cluster')\n",
    "axes[3].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 5. Contract type by cluster\n",
    "contract_cluster = pd.crosstab(df_clustered['Cluster'], df_clustered['Contract'], normalize='index')\n",
    "contract_cluster.plot(kind='bar', stacked=True, ax=axes[4])\n",
    "axes[4].set_title('Contract Type Distribution by Cluster')\n",
    "axes[4].set_xlabel('Cluster')\n",
    "axes[4].legend(title='Contract', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[4].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 6. Internet service by cluster\n",
    "internet_cluster = pd.crosstab(df_clustered['Cluster'], df_clustered['InternetService'], normalize='index')\n",
    "internet_cluster.plot(kind='bar', stacked=True, ax=axes[5])\n",
    "axes[5].set_title('Internet Service by Cluster')\n",
    "axes[5].set_xlabel('Cluster')\n",
    "axes[5].legend(title='Internet Service', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "axes[5].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/cluster_comprehensive_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predictive Model for Product Recommendations\n",
    "\n",
    "### Challenge 5: Building a Model that Works with Both Data Types\n",
    "We'll create a model to predict which customers are likely to purchase additional services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable for service uptake prediction\n",
    "# Let's predict likelihood of having high-value services (streaming services)\n",
    "df_model = df_clustered.copy()\n",
    "df_model['high_value_customer'] = ((df_model['StreamingTV'] == 'Yes') | \n",
    "                                  (df_model['StreamingMovies'] == 'Yes')).astype(int)\n",
    "\n",
    "print(f\"High-value customer distribution:\")\n",
    "print(df_model['high_value_customer'].value_counts())\n",
    "print(f\"High-value customer rate: {df_model['high_value_customer'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for prediction model\n",
    "feature_cols = ['tenure', 'MonthlyCharges', 'TotalCharges', 'SeniorCitizen', \n",
    "               'total_services', 'Cluster']\n",
    "\n",
    "# Add important categorical features (encoded)\n",
    "categorical_for_model = ['gender', 'Partner', 'Dependents', 'Contract', 'InternetService']\n",
    "\n",
    "# Create dummy variables for categorical features\n",
    "df_model_encoded = pd.get_dummies(df_model[feature_cols + categorical_for_model], \n",
    "                                 columns=categorical_for_model, drop_first=True)\n",
    "\n",
    "X = df_model_encoded\n",
    "y = df_model['high_value_customer']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Features: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train Random Forest model (handles mixed data types well)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"MODEL PERFORMANCE:\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")\n",
    "print(f\"Recall: {recall:.3f}\")\n",
    "print(f\"F1-Score: {f1:.3f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=feature_importance.head(15), y='feature', x='importance')\n",
    "plt.title('Top 15 Most Important Features for High-Value Customer Prediction')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visualizations/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "display(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Business Insights and Cluster Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed cluster profiles for business insights\n",
    "def generate_cluster_insights(df, cluster_col='Cluster'):\n",
    "    \"\"\"Generate business insights for each cluster\"\"\"\n",
    "    \n",
    "    insights = {}\n",
    "    \n",
    "    for cluster in sorted(df[cluster_col].unique()):\n",
    "        cluster_data = df[df[cluster_col] == cluster]\n",
    "        \n",
    "        insights[cluster] = {\n",
    "            'size': len(cluster_data),\n",
    "            'percentage': len(cluster_data) / len(df) * 100,\n",
    "            'avg_tenure': cluster_data['tenure'].mean(),\n",
    "            'avg_monthly_charges': cluster_data['MonthlyCharges'].mean(),\n",
    "            'avg_total_charges': cluster_data['TotalCharges'].mean(),\n",
    "            'churn_rate': (cluster_data['Churn'] == 'Yes').mean() * 100,\n",
    "            'senior_citizen_rate': cluster_data['SeniorCitizen'].mean() * 100,\n",
    "            'partner_rate': (cluster_data['Partner'] == 'Yes').mean() * 100,\n",
    "            'dependents_rate': (cluster_data['Dependents'] == 'Yes').mean() * 100,\n",
    "            'internet_fiber': (cluster_data['InternetService'] == 'Fiber optic').mean() * 100,\n",
    "            'internet_dsl': (cluster_data['InternetService'] == 'DSL').mean() * 100,\n",
    "            'no_internet': (cluster_data['InternetService'] == 'No').mean() * 100,\n",
    "            'monthly_contract': (cluster_data['Contract'] == 'Month-to-month').mean() * 100,\n",
    "            'one_year_contract': (cluster_data['Contract'] == 'One year').mean() * 100,\n",
    "            'two_year_contract': (cluster_data['Contract'] == 'Two year').mean() * 100,\n",
    "            'avg_total_services': cluster_data['total_services'].mean(),\n",
    "            'streaming_tv': (cluster_data['StreamingTV'] == 'Yes').mean() * 100,\n",
    "            'streaming_movies': (cluster_data['StreamingMovies'] == 'Yes').mean() * 100,\n",
    "            'high_value_rate': cluster_data['high_value_customer'].mean() * 100\n",
    "        }\n",
    "    \n",
    "    return insights\n",
    "\n",
    "cluster_insights = generate_cluster_insights(df_model)\n",
    "\n",
    "# Display insights in a formatted way\n",
    "print(\"=\" * 80)\n",
    "print(\"DETAILED CLUSTER BUSINESS INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cluster, data in cluster_insights.items():\n",
    "    print(f\"\\n📊 CLUSTER {cluster} ({data['size']} customers, {data['percentage']:.1f}% of total)\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"💰 Financial Profile:\")\n",
    "    print(f\"   • Average Monthly Charges: ${data['avg_monthly_charges']:.2f}\")\n",
    "    print(f\"   • Average Total Charges: ${data['avg_total_charges']:.2f}\")\n",
    "    print(f\"   • Average Tenure: {data['avg_tenure']:.1f} months\")\n",
    "    \n",
    "    print(f\"\\n👥 Demographics:\")\n",
    "    print(f\"   • Senior Citizens: {data['senior_citizen_rate']:.1f}%\")\n",
    "    print(f\"   • Have Partner: {data['partner_rate']:.1f}%\")\n",
    "    print(f\"   • Have Dependents: {data['dependents_rate']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n📱 Service Usage:\")\n",
    "    print(f\"   • Fiber Optic Internet: {data['internet_fiber']:.1f}%\")\n",
    "    print(f\"   • DSL Internet: {data['internet_dsl']:.1f}%\")\n",
    "    print(f\"   • No Internet: {data['no_internet']:.1f}%\")\n",
    "    print(f\"   • Average Services: {data['avg_total_services']:.1f}\")\n",
    "    print(f\"   • Streaming TV: {data['streaming_tv']:.1f}%\")\n",
    "    print(f\"   • Streaming Movies: {data['streaming_movies']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n📋 Contract & Loyalty:\")\n",
    "    print(f\"   • Month-to-month: {data['monthly_contract']:.1f}%\")\n",
    "    print(f\"   • One Year: {data['one_year_contract']:.1f}%\")\n",
    "    print(f\"   • Two Year: {data['two_year_contract']:.1f}%\")\n",
    "    print(f\"   • Churn Rate: {data['churn_rate']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n🎯 Business Value:\")\n",
    "    print(f\"   • High-Value Customer Rate: {data['high_value_rate']:.1f}%\")\n",
    "    print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Business Recommendations and Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive recommendations report\n",
    "def create_business_recommendations(insights):\n",
    "    \"\"\"Generate business recommendations based on cluster analysis\"\"\"\n",
    "    \n",
    "    recommendations = {}\n",
    "    \n",
    "    # Analyze each cluster and provide specific recommendations\n",
    "    for cluster, data in insights.items():\n",
    "        recs = []\n",
    "        \n",
    "        # Revenue-based recommendations\n",
    "        if data['avg_monthly_charges'] > 70:\n",
    "            recs.append(\"🏆 Premium segment - Focus on retention with VIP treatment\")\n",
    "        elif data['avg_monthly_charges'] < 40:\n",
    "            recs.append(\"📈 Low-revenue segment - Upselling opportunity\")\n",
    "        \n",
    "        # Churn-based recommendations\n",
    "        if data['churn_rate'] > 30:\n",
    "            recs.append(\"⚠️ High churn risk - Implement retention campaigns\")\n",
    "        elif data['churn_rate'] < 15:\n",
    "            recs.append(\"✅ Low churn - Stable segment for cross-selling\")\n",
    "        \n",
    "        # Service adoption recommendations\n",
    "        if data['avg_total_services'] < 3:\n",
    "            recs.append(\"📊 Low service adoption - Target for bundling offers\")\n",
    "        \n",
    "        # Contract recommendations\n",
    "        if data['monthly_contract'] > 50:\n",
    "            recs.append(\"📝 High month-to-month - Offer long-term contract incentives\")\n",
    "        \n",
    "        # Internet service recommendations\n",
    "        if data['internet_dsl'] > data['internet_fiber'] and data['internet_dsl'] > 50:\n",
    "            recs.append(\"🚀 DSL dominant - Promote fiber optic upgrades\")\n",
    "        \n",
    "        # Demographics-based recommendations\n",
    "        if data['senior_citizen_rate'] > 30:\n",
    "            recs.append(\"👴 Senior-heavy segment - Tailor senior-friendly services\")\n",
    "        \n",
    "        # Streaming services recommendations\n",
    "        if data['streaming_tv'] < 30 and data['internet_fiber'] > 40:\n",
    "            recs.append(\"📺 Low streaming adoption with fiber - Promote streaming packages\")\n",
    "        \n",
    "        recommendations[cluster] = recs\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "business_recs = create_business_recommendations(cluster_insights)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🎯 TARGETED BUSINESS RECOMMENDATIONS BY CUSTOMER SEGMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cluster, recs in business_recs.items():\n",
    "    data = cluster_insights[cluster]\n",
    "    print(f\"\\nCLUSTER {cluster} STRATEGY ({data['size']} customers):\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, rec in enumerate(recs, 1):\n",
    "        print(f\"{i}. {rec}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cluster assignments and predictions for business use\n",
    "df_final = df_model.copy()\n",
    "df_final['predicted_high_value'] = rf_model.predict(X)\n",
    "df_final['high_value_probability'] = rf_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Create priority scoring\n",
    "df_final['priority_score'] = (\n",
    "    df_final['high_value_probability'] * 0.4 +  # Likelihood of being high-value\n",
    "    (df_final['MonthlyCharges'] / df_final['MonthlyCharges'].max()) * 0.3 +  # Revenue potential\n",
    "    (1 - (df_final['Churn'] == 'Yes').astype(int)) * 0.3  # Retention likelihood\n",
    ")\n",
    "\n",
    "# Save results\n",
    "df_final[['customerID', 'Cluster', 'predicted_high_value', 'high_value_probability', 'priority_score']].to_csv(\n",
    "    '../data/customer_segments_with_predictions.csv', index=False\n",
    ")\n",
    "\n",
    "print(\"Results saved to: ../data/customer_segments_with_predictions.csv\")\n",
    "print(f\"\\nTop 10 Priority Customers for Upselling:\")\n",
    "display(df_final.nlargest(10, 'priority_score')[['customerID', 'Cluster', 'MonthlyCharges', \n",
    "                                                 'tenure', 'high_value_probability', 'priority_score']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

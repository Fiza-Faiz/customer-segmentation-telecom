"""
Customer Segmentation Models Module

This module contains various clustering algorithms and evaluation methods
specifically designed for customer segmentation tasks with mixed data types.

Key Features:
1. Multiple clustering algorithms (K-Means, Hierarchical, Gaussian Mixture)
2. Automatic optimal cluster number detection
3. Cluster evaluation and interpretation
4. Business-oriented cluster profiling
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')


class CustomerSegmentationModel:
    """
    A comprehensive customer segmentation model that handles multiple
    clustering algorithms and provides business-oriented insights.
    """
    
    def __init__(self):
        self.model = None
        self.model_type = None
        self.n_clusters = None
        self.cluster_labels = None
        self.evaluation_scores = {}
        self.cluster_profiles = None
        
    def find_optimal_clusters(self, X, max_clusters=10, methods=['silhouette', 'elbow']):
        """
        Find optimal number of clusters using multiple methods
        
        Args:
            X: preprocessed feature matrix
            max_clusters: maximum number of clusters to test
            methods: list of methods to use ('silhouette', 'elbow', 'calinski')
            
        Returns:
            dict: results from different methods
        """
        results = {}
        k_range = range(2, max_clusters + 1)
        
        if 'silhouette' in methods:
            silhouette_scores = []
            for k in k_range:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                labels = kmeans.fit_predict(X)
                score = silhouette_score(X, labels)
                silhouette_scores.append(score)
            
            results['silhouette'] = {
                'scores': silhouette_scores,
                'optimal_k': k_range[np.argmax(silhouette_scores)],
                'best_score': max(silhouette_scores)
            }
        
        if 'elbow' in methods:
            inertias = []
            for k in k_range:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                kmeans.fit(X)
                inertias.append(kmeans.inertia_)
            
            # Simple elbow detection (can be improved with more sophisticated methods)
            diffs = np.diff(inertias)
            elbow_k = k_range[np.argmin(diffs[1:]) + 2]  # +2 to account for indexing
            
            results['elbow'] = {
                'inertias': inertias,
                'optimal_k': elbow_k
            }
        
        if 'calinski' in methods:
            calinski_scores = []
            for k in k_range:
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                labels = kmeans.fit_predict(X)
                score = calinski_harabasz_score(X, labels)
                calinski_scores.append(score)\n            \n            results['calinski'] = {\n                'scores': calinski_scores,\n                'optimal_k': k_range[np.argmax(calinski_scores)],\n                'best_score': max(calinski_scores)\n            }\n        \n        return results\n    \n    def plot_cluster_analysis(self, results, save_path=None):\n        \"\"\"\n        Plot cluster optimization results\n        \n        Args:\n            results: results from find_optimal_clusters\n            save_path: path to save the plot\n        \"\"\"\n        n_methods = len(results)\n        fig, axes = plt.subplots(1, n_methods, figsize=(5 * n_methods, 5))\n        \n        if n_methods == 1:\n            axes = [axes]\n        \n        for i, (method, data) in enumerate(results.items()):\n            ax = axes[i]\n            \n            if method == 'silhouette':\n                k_range = range(2, len(data['scores']) + 2)\n                ax.plot(k_range, data['scores'], 'bo-', linewidth=2, markersize=8)\n                ax.axvline(data['optimal_k'], color='red', linestyle='--', \n                          label=f'Optimal k={data[\"optimal_k\"]}')\n                ax.set_xlabel('Number of Clusters')\n                ax.set_ylabel('Silhouette Score')\n                ax.set_title('Silhouette Analysis')\n                ax.legend()\n                ax.grid(True, alpha=0.3)\n                \n            elif method == 'elbow':\n                k_range = range(2, len(data['inertias']) + 2)\n                ax.plot(k_range, data['inertias'], 'ro-', linewidth=2, markersize=8)\n                ax.axvline(data['optimal_k'], color='blue', linestyle='--', \n                          label=f'Elbow k={data[\"optimal_k\"]}')\n                ax.set_xlabel('Number of Clusters')\n                ax.set_ylabel('Inertia (WCSS)')\n                ax.set_title('Elbow Method')\n                ax.legend()\n                ax.grid(True, alpha=0.3)\n                \n            elif method == 'calinski':\n                k_range = range(2, len(data['scores']) + 2)\n                ax.plot(k_range, data['scores'], 'go-', linewidth=2, markersize=8)\n                ax.axvline(data['optimal_k'], color='orange', linestyle='--', \n                          label=f'Optimal k={data[\"optimal_k\"]}')\n                ax.set_xlabel('Number of Clusters')\n                ax.set_ylabel('Calinski-Harabasz Score')\n                ax.set_title('Calinski-Harabasz Analysis')\n                ax.legend()\n                ax.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        plt.show()\n    \n    def fit_clustering_model(self, X, n_clusters, algorithm='kmeans', **kwargs):\n        \"\"\"\n        Fit a clustering model to the data\n        \n        Args:\n            X: preprocessed feature matrix\n            n_clusters: number of clusters\n            algorithm: clustering algorithm ('kmeans', 'hierarchical', 'gmm')\n            **kwargs: additional parameters for the clustering algorithm\n            \n        Returns:\n            fitted model and cluster labels\n        \"\"\"\n        self.n_clusters = n_clusters\n        self.model_type = algorithm\n        \n        if algorithm == 'kmeans':\n            self.model = KMeans(n_clusters=n_clusters, random_state=42, \n                               n_init=10, **kwargs)\n        elif algorithm == 'hierarchical':\n            self.model = AgglomerativeClustering(n_clusters=n_clusters, **kwargs)\n        elif algorithm == 'gmm':\n            self.model = GaussianMixture(n_components=n_clusters, random_state=42, **kwargs)\n        else:\n            raise ValueError(f\"Unsupported algorithm: {algorithm}\")\n        \n        # Fit the model\n        if algorithm == 'gmm':\n            self.cluster_labels = self.model.fit_predict(X)\n        else:\n            self.cluster_labels = self.model.fit_predict(X)\n        \n        # Calculate evaluation metrics\n        self.evaluation_scores = {\n            'silhouette': silhouette_score(X, self.cluster_labels),\n            'calinski_harabasz': calinski_harabasz_score(X, self.cluster_labels),\n            'davies_bouldin': davies_bouldin_score(X, self.cluster_labels)\n        }\n        \n        return self.model, self.cluster_labels\n    \n    def create_cluster_profiles(self, df_original, cluster_labels, \n                              numerical_features, categorical_features):\n        \"\"\"\n        Create comprehensive cluster profiles for business interpretation\n        \n        Args:\n            df_original: original dataframe with meaningful column names\n            cluster_labels: cluster assignments\n            numerical_features: list of numerical feature names\n            categorical_features: list of categorical feature names\n            \n        Returns:\n            dict: cluster profiles with business metrics\n        \"\"\"\n        df_with_clusters = df_original.copy()\n        df_with_clusters['Cluster'] = cluster_labels\n        \n        profiles = {}\n        \n        for cluster in sorted(df_with_clusters['Cluster'].unique()):\n            cluster_data = df_with_clusters[df_with_clusters['Cluster'] == cluster]\n            \n            profile = {\n                'size': len(cluster_data),\n                'percentage': len(cluster_data) / len(df_with_clusters) * 100,\n                'numerical_stats': {},\n                'categorical_stats': {}\n            }\n            \n            # Numerical features analysis\n            for feature in numerical_features:\n                if feature in cluster_data.columns:\n                    profile['numerical_stats'][feature] = {\n                        'mean': cluster_data[feature].mean(),\n                        'median': cluster_data[feature].median(),\n                        'std': cluster_data[feature].std()\n                    }\n            \n            # Categorical features analysis\n            for feature in categorical_features:\n                if feature in cluster_data.columns:\n                    value_counts = cluster_data[feature].value_counts(normalize=True) * 100\n                    profile['categorical_stats'][feature] = value_counts.to_dict()\n            \n            profiles[cluster] = profile\n        \n        self.cluster_profiles = profiles\n        return profiles\n    \n    def generate_business_insights(self, profiles):\n        \"\"\"\n        Generate business insights from cluster profiles\n        \n        Args:\n            profiles: cluster profiles from create_cluster_profiles\n            \n        Returns:\n            dict: business insights for each cluster\n        \"\"\"\n        insights = {}\n        \n        for cluster, profile in profiles.items():\n            cluster_insights = {\n                'segment_name': self._generate_segment_name(profile),\n                'key_characteristics': self._identify_key_characteristics(profile),\n                'business_value': self._assess_business_value(profile),\n                'recommended_actions': self._generate_recommendations(profile)\n            }\n            insights[cluster] = cluster_insights\n        \n        return insights\n    \n    def _generate_segment_name(self, profile):\n        \"\"\"Generate a descriptive name for the customer segment\"\"\"\n        # This is a simplified version - can be made more sophisticated\n        size_desc = \"Large\" if profile['percentage'] > 30 else \"Medium\" if profile['percentage'] > 15 else \"Small\"\n        \n        # Look for distinguishing characteristics\n        if 'MonthlyCharges' in profile['numerical_stats']:\n            avg_charges = profile['numerical_stats']['MonthlyCharges']['mean']\n            if avg_charges > 70:\n                value_desc = \"Premium\"\n            elif avg_charges < 40:\n                value_desc = \"Budget\"\n            else:\n                value_desc = \"Standard\"\n        else:\n            value_desc = \"General\"\n        \n        return f\"{value_desc} {size_desc} Segment\"\n    \n    def _identify_key_characteristics(self, profile):\n        \"\"\"Identify key characteristics of the cluster\"\"\"\n        characteristics = []\n        \n        # Revenue characteristics\n        if 'MonthlyCharges' in profile['numerical_stats']:\n            avg_revenue = profile['numerical_stats']['MonthlyCharges']['mean']\n            if avg_revenue > 70:\n                characteristics.append(\"High revenue customers\")\n            elif avg_revenue < 40:\n                characteristics.append(\"Low revenue customers\")\n        \n        # Tenure characteristics\n        if 'tenure' in profile['numerical_stats']:\n            avg_tenure = profile['numerical_stats']['tenure']['mean']\n            if avg_tenure > 36:\n                characteristics.append(\"Long-term customers\")\n            elif avg_tenure < 12:\n                characteristics.append(\"New customers\")\n        \n        # Churn risk\n        if 'Churn' in profile['categorical_stats']:\n            churn_rate = profile['categorical_stats']['Churn'].get('Yes', 0)\n            if churn_rate > 30:\n                characteristics.append(\"High churn risk\")\n            elif churn_rate < 15:\n                characteristics.append(\"Low churn risk\")\n        \n        return characteristics\n    \n    def _assess_business_value(self, profile):\n        \"\"\"Assess the business value of the segment\"\"\"\n        value_score = 0\n        \n        # Revenue contribution\n        if 'MonthlyCharges' in profile['numerical_stats']:\n            avg_revenue = profile['numerical_stats']['MonthlyCharges']['mean']\n            value_score += min(avg_revenue / 100, 1) * 0.4  # Max 0.4 points for revenue\n        \n        # Size contribution\n        size_contribution = profile['percentage'] / 100\n        value_score += size_contribution * 0.3  # Max 0.3 points for size\n        \n        # Loyalty (inverse of churn)\n        if 'Churn' in profile['categorical_stats']:\n            churn_rate = profile['categorical_stats']['Churn'].get('Yes', 0) / 100\n            loyalty_score = 1 - churn_rate\n            value_score += loyalty_score * 0.3  # Max 0.3 points for loyalty\n        \n        # Classify business value\n        if value_score > 0.7:\n            return \"High Value\"\n        elif value_score > 0.4:\n            return \"Medium Value\"\n        else:\n            return \"Low Value\"\n    \n    def _generate_recommendations(self, profile):\n        \"\"\"Generate business recommendations for the segment\"\"\"\n        recommendations = []\n        \n        # Revenue-based recommendations\n        if 'MonthlyCharges' in profile['numerical_stats']:\n            avg_revenue = profile['numerical_stats']['MonthlyCharges']['mean']\n            if avg_revenue < 40:\n                recommendations.append(\"Target for upselling and cross-selling\")\n            elif avg_revenue > 70:\n                recommendations.append(\"Focus on retention with premium support\")\n        \n        # Churn-based recommendations\n        if 'Churn' in profile['categorical_stats']:\n            churn_rate = profile['categorical_stats']['Churn'].get('Yes', 0)\n            if churn_rate > 30:\n                recommendations.append(\"Implement proactive retention campaigns\")\n            elif churn_rate < 15:\n                recommendations.append(\"Leverage for referral programs\")\n        \n        # Contract-based recommendations\n        if 'Contract' in profile['categorical_stats']:\n            monthly_rate = profile['categorical_stats']['Contract'].get('Month-to-month', 0)\n            if monthly_rate > 60:\n                recommendations.append(\"Offer long-term contract incentives\")\n        \n        return recommendations\n    \n    def visualize_clusters(self, X, cluster_labels, save_path=None):\n        \"\"\"\n        Visualize clusters using PCA dimensionality reduction\n        \n        Args:\n            X: preprocessed feature matrix\n            cluster_labels: cluster assignments\n            save_path: path to save the plot\n        \"\"\"\n        # Apply PCA for visualization\n        pca = PCA(n_components=2)\n        X_pca = pca.fit_transform(X)\n        \n        plt.figure(figsize=(12, 8))\n        colors = plt.cm.Set3(np.linspace(0, 1, self.n_clusters))\n        \n        for i in range(self.n_clusters):\n            cluster_points = X_pca[cluster_labels == i]\n            plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n                       c=[colors[i]], label=f'Cluster {i}', \n                       alpha=0.7, s=50)\n        \n        plt.xlabel(f'First Principal Component (Var: {pca.explained_variance_ratio_[0]:.2%})')\n        plt.ylabel(f'Second Principal Component (Var: {pca.explained_variance_ratio_[1]:.2%})')\n        plt.title('Customer Segments Visualization (PCA)')\n        plt.legend()\n        plt.grid(True, alpha=0.3)\n        \n        if save_path:\n            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        plt.show()\n    \n    def get_evaluation_report(self):\n        \"\"\"\n        Get a comprehensive evaluation report of the clustering model\n        \n        Returns:\n            dict: evaluation metrics and summary\n        \"\"\"\n        report = {\n            'model_type': self.model_type,\n            'n_clusters': self.n_clusters,\n            'evaluation_scores': self.evaluation_scores,\n            'cluster_sizes': pd.Series(self.cluster_labels).value_counts().sort_index().to_dict()\n        }\n        \n        # Add interpretation of scores\n        report['score_interpretation'] = {\n            'silhouette': self._interpret_silhouette_score(self.evaluation_scores['silhouette']),\n            'calinski_harabasz': \"Higher is better (cluster separation)\",\n            'davies_bouldin': \"Lower is better (cluster compactness)\"\n        }\n        \n        return report\n    \n    def _interpret_silhouette_score(self, score):\n        \"\"\"Interpret silhouette score\"\"\"\n        if score > 0.7:\n            return \"Excellent clustering structure\"\n        elif score > 0.5:\n            return \"Good clustering structure\"\n        elif score > 0.25:\n            return \"Weak clustering structure\"\n        else:\n            return \"Poor clustering structure\"\n\n\ndef compare_clustering_algorithms(X, n_clusters, algorithms=['kmeans', 'hierarchical', 'gmm']):\n    \"\"\"\n    Compare different clustering algorithms on the same dataset\n    \n    Args:\n        X: preprocessed feature matrix\n        n_clusters: number of clusters to use\n        algorithms: list of algorithms to compare\n        \n    Returns:\n        dict: comparison results\n    \"\"\"\n    results = {}\n    \n    for algorithm in algorithms:\n        model = CustomerSegmentationModel()\n        model.fit_clustering_model(X, n_clusters, algorithm)\n        \n        results[algorithm] = {\n            'model': model,\n            'labels': model.cluster_labels,\n            'scores': model.evaluation_scores\n        }\n    \n    return results"
